

# Load the required library
library(bnlearn)

# Step 1: Read Data
data.grades <- read.table("2020_bn_nb_data.txt", header = TRUE)

# Function to split data into training and testing sets
split_data function(data, train_size) {
    n <- nrow(data)
    train_indices <- sample(1:n, size = floor(train size * n))
    train_data <- data[train_indices, ]
    test_data <- data[-train_indices, ]
    return(list(train_data = train_data, test_data = test_data))
}

# Function to train and test the Bayesian network classifier
train_and_test_bn <- function(train_data, test_data) {
    # Learn the structure of the Bayesian network using Hill-Climbing with BIC score
     bn_structure <- hc(train_data, score = "bic")

    # Handle level mismatch in PH160:
    # Identify valid levels in the data and training set
    valid_levels <- intersect(levels(train_data$PH160), levels(test_data$PH160))

    # Remove unused levels
    train_data$PH160 <- factor(train_data$PH160, levels = valid_levels)
    trest_data$PH160 <- factor(train_data$PH160, levels = valid_levels)

    # Learn the Conditional Probability Tables (CPTs) for each node
    bn_params <- bn.fit(bn_structure, train_data)

   # Predict on test data
   predictions <- predict(bn_params, node = "QP", method = "bayes -lw", data = test_data)

   # Calculate accuracy
   accuracy <- sum(predictions == test_data$QP) / nrow(test_data)

   return (accuracy)
}


# Number of iterations
num iterations <- 20

# Store accuracies
accuracies <- numeric(num_iterations)

# Run experiments
for (i in l:num_iterations){
    # Split data into training and testing sets
    split <- split_data(data, 0.7)

    # Train and test naive Bayes classifier
    accuracies[i] train_and_test_nb(split$train_data, split$test_data)
}

# Report results
cat("Mean accuracy:" , mean(accuracies),"\n")
cat("standard deviation of accuracy:", sd(accuracies) ,"\n")
